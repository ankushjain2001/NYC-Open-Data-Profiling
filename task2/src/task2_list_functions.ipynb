{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# --- NOTES -------------------------------------------------------------------\n",
    "# 1. Update the datasets, dataList\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pyspark\n",
    "from ast import literal_eval\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession, Row\n",
    "from pyspark.sql.functions import udf, unix_timestamp, col ,length\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, FloatType, DateType, TimestampType\n",
    "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline \n",
    "from collections import Counter\n",
    "#import spacy\n",
    "#from spacy import displacy\n",
    "#import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# --- Function Definitions Begin ----------------------------------------------\n",
    "\n",
    "# Function to find mean and stdv for all files\n",
    "def mean_stdv(df):\n",
    "    unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n",
    "    for i in [\"count\"]:\n",
    "        assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
    "        scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
    "        pipeline = Pipeline(stages=[assembler, scaler])\n",
    "        df = pipeline.fit(df).transform(df).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\")).drop(i+\"_Vect\")\n",
    "        df_stats = df.select(_mean(col('count_Scaled')).alias('mean'),_stddev(col('count_Scaled')).alias('std')).collect()\n",
    "        mean = df_stats[0]['mean']\n",
    "        std = df_stats[0]['std']\n",
    "        return df_stats \n",
    "\n",
    "# Function to sum all count of values for all files\n",
    "def count_all_values(df):\n",
    "    res = df.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "    return res\n",
    "\n",
    "# Regex function to check website type\n",
    "def re_find_website(df,count_all,found_type):\n",
    "    web_re_rexpr = \"WWW\\.|\\.COM|HTTP\\:\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(web_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.85): \n",
    "            found_type = found_type + [\"website\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function to check zip type\n",
    "def re_find_zipCode(df,count_all,found_type):\n",
    "    zip_re_rexpr = \"^\\d{5}?$|^\\d{5}?-\\d\\d\\d$|^\\d{8}?$\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(zip_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.85): \n",
    "            found_type = found_type + [\"zip_code\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function to check buildingCode type\n",
    "def re_find_buildingCode(df,count_all,found_type):\n",
    "    bc_re_rexpr = \"([A-Z])\\d\\-\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(bc_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.85): \n",
    "            found_type = found_type + [\"building_classification\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0 \n",
    "\n",
    "# Regex function to check phone number type\n",
    "def re_find_phoneNum(df,count_all,found_type):\n",
    "    phone_re_rexpr = \"^\\d{10}?$|^\\(\\d\\d\\d\\)\\d\\d\\d\\d\\d\\d\\d$|^\\d\\d\\d\\-\\d\\d\\d\\-\\d\\d\\d\\d$\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(phone_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.85): \n",
    "            found_type = found_type + [\"phone_number\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function to check lat_lon type\n",
    "def re_find_lat_lon(df,count_all,found_type):\n",
    "    ll_re_rexpr = \"\\([-+]?[0-9]+\\.[0-9]+\\,\\s*[-+]?[0-9]+\\.[0-9]+\\)\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(ll_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.85): \n",
    "            found_type = found_type + [\"lat_lon_cord\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function to check street_addrees type\n",
    "def re_find_street_address(df,count_all,col_length,found_type):\n",
    "    st_re_rexpr = \"\\sROAD|\\sSTREET|\\sPLACE|\\sDRIVE|\\sBLVD|\\sST|\\sRD|\\sDR|\\sAVENUE|\\sAVE\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(st_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.8): \n",
    "            if (col_length >= 15):\n",
    "                found_type = found_type + [\"address\"]\n",
    "            elif (col_length < 15):\n",
    "                found_type = found_type + [\"street\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function to check school name type\n",
    "def re_find_school(df,count_all,found_type):\n",
    "    school_re_rexpr = \"\\sSCHOOL|\\sACADEMY|HS\\s|ACAD|I.S.\\s|IS\\s|M.S.\\s|P.S\\s|PS\\s|ACADEMY\\s\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(school_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.5): \n",
    "            found_type = found_type + [\"school_name\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function for checking house number \n",
    "def re_find_houseNo(df,count_all,found_type):\n",
    "    houseNo_re_rexpr = \"^\\d{2}?$|^\\d{3}?$|^\\d{4}?$\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(houseNo_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.85): \n",
    "            found_type = found_type + [\"house number\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function for checking school subject\n",
    "def re_find_school_subject(df,count_all,found_type):\n",
    "    school_subj_re_rexpr = \"^ENGLISH$|^ENGLISH\\s[0-9]?$|^MATH\\s[A-Z$]|^MATH$|^SCIENCE$|^SOCIAL\\sSTUDIES$|^ALGEBRA\\s[A-Z]$|\\\n",
    "                            ^CHEMISTRY$|^ASSUMED\\sTEAM\\sTEACHING$|^EARTH\\sSCIENCE$|^GEOMETRY$|^ECONOMICS$|^GLOBAL HISTORY$|\\\n",
    "                            ^GLOBAL\\sHISTORY[A-Z]$|^LIVING ENVIRONMENT$|^PHYSICS$|^US\\sGOVERNMENT$|^US\\sGOVERNMENT$|^US\\sGOVERNMENT\\s&|\\\n",
    "                            ^US\\SHISTORY$|^GLOBAL HISTORY\\s[0-9]?$\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(school_subj_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        print(res)\n",
    "        if (res >= 0.5): \n",
    "            found_type = found_type + [\"school subject\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# Regex function for checking school level \n",
    "def re_find_schoolLevel(df,count_all,found_type):\n",
    "    schlvl_re_rexpr = \"^[K]\\-\\d?$|^HIGH SCHOOL$|^ELEMENTARY$|^ELEMENTARY SCHOOL$|^MIDDLE SCHOOL$|^TRANSFER\\sSCHOOL$|^MIDDLE$|^HIGH\\sSCHOOL\\sTRANSFERL$|^YABC$|^[K]\\-[0-9]{2}$\"\n",
    "    df_filtered = df.filter(df[\"val\"].rlike(schlvl_re_rexpr))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        if (res >= 0.85): \n",
    "            found_type = found_type + [\"school level\"]\n",
    "        return res, found_type, count_filtered\n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "# --- Functions FOR NLP Starts HERE -------------------------------------------\n",
    "def nlp_find_person(df,count_all,found_type):\n",
    "    #Your Code HERE: \n",
    "    #Use count_all for percentage calculation\n",
    "    #Please return two values: (1)percentage of such type in this col AND (2)the type found for this column\n",
    "    #if found:\n",
    "#         found_type = found_type + [\"person\"]\n",
    "    #if not found:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_business_name(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_vehicle_type(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_color(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_car_make(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_car_model(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_neighborhood(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_borough(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "def nlp_find_city(df,count_all,found_type):\n",
    "    #Your Code HERE:\n",
    "    return 0, found_type, 0\n",
    "\n",
    "# --- Function FOR NLP End ------------------------------------------------\n",
    "\n",
    "# --- Functions FOR LIST COMPARISON Starts HERE -------------------------------\n",
    "def list_find_school_subject(df,count_all,found_type):\n",
    "    df_filtered = df.filter(df[\"val\"].isin(ss_keywords))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        print(res)\n",
    "        if (res >= 0.4): \n",
    "            found_type = found_type + [\"school subject\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "def list_find_business_name(df,count_all,found_type):\n",
    "    #Your Code HERE: \n",
    "    return 0, found_type, 0\n",
    "\n",
    "def list_find_neighborhood(df,count_all,found_type):\n",
    "    df_filtered = df.filter(df[\"val\"].isin(nh_keywords))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        print(res)\n",
    "        if (res >= 0.1): \n",
    "            found_type = found_type + [\"neighborhood\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "def list_find_area_of_study(df,count_all,found_type):\n",
    "    df_filtered = df.filter(df[\"val\"].isin(aos_keywords))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        print(res)\n",
    "        if (res >= 0.3): \n",
    "            found_type = found_type + [\"area of study\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "    \n",
    "\n",
    "def list_find_agency(df,count_all,found_type):\n",
    "    df_filtered = df.filter(df[\"val\"].isin(ca_keywords))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        print(res)\n",
    "        if (res >= 0.1): \n",
    "            found_type = found_type + [\"city agency\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "def list_find_location_type(df,count_all,found_type):\n",
    "    df_filtered = df.filter(df[\"val\"].isin(lt_keywords))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        print(res)\n",
    "        if (res >= 0.1): \n",
    "            found_type = found_type + [\"location type\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "def list_find_parks_playgrounds(df,count_all,found_type):\n",
    "    df_filtered = df.filter(df[\"val\"].isin(pp_keywords))\n",
    "    if (df_filtered.count() is not 0):\n",
    "        count_filtered = df_filtered.rdd.map(lambda x: (1,x[1])).reduceByKey(lambda x,y: x + y).collect()[0][1]\n",
    "        res = float(count_filtered/count_all)\n",
    "        print(res)\n",
    "        if (res >= 0.1): \n",
    "            found_type = found_type + [\"parks and playgrounds\"]\n",
    "        return res, found_type, count_filtered \n",
    "    else:\n",
    "        return 0, found_type, 0\n",
    "\n",
    "def import_keyword_list(inputDir):\n",
    "    klist = sc.textFile(inputDir)\n",
    "    klist = klist.flatMap(lambda x: x.split(\",\")).collect()\n",
    "    klist = [x.strip('\"') for x in klist]\n",
    "    klist = [re.sub(\"\\[|\\]|\\'|\\'|\" \"\", \"\", item)for item in klist]\n",
    "    klist = [re.sub(\" \" \"\", \"\", item)for item in klist]\n",
    "    return(klist)\n",
    "\n",
    "\n",
    "# --- Function Definitions End ------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# --- MAIN --------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Setting spark context and \n",
    "    sc = SparkContext()\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"project_task2\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    sqlContext = SQLContext(sparkContext=spark.sparkContext, sparkSession=spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    # Current user path\n",
    "    env_var = os.environ\n",
    "    this_user = env_var['USER']\n",
    "\n",
    "    # Input & output directories\n",
    "    #inputDirectory = \"/user/hm74/NYCColumns/\"#sys.argv[1]\n",
    "    #outputDirectory = \"/user/\" + this_user + \"/project/task2/\"#sys.argv[2]\n",
    "    inputDirectory = \"/home/ted/school/big_data/project/big_data_course_project/task2/raw_data/\"\n",
    "    inputFileClusters = \"/home/ted/school/big_data/project/big_data_course_project/task2/resources/filename_clusters.json\"\n",
    "    input_pp_keywords = \"park_playground_keywords\"\n",
    "    input_aos_keywords = \"area_of_study_keywords\"\n",
    "    input_ca_keywords = \"city_agency_keywords\"\n",
    "    input_ss_keywords = \"school_subject_keywords\"\n",
    "    input_sn_keywords = \"school_name_keywords\"\n",
    "    input_lt_keywords = \"location_type_keywords\"\n",
    "    input_nh_keywords = \"neighborhood_keywords\"\n",
    "    \n",
    "    pp_keywords = import_keyword_list(input_pp_keywords) # parks & playgrounds\n",
    "    aos_keywords = import_keyword_list(input_aos_keywords) # area of study\n",
    "    ca_keywords = import_keyword_list(input_ca_keywords) # city agency\n",
    "    ss_keywords = import_keyword_list(input_ss_keywords) # school subject\n",
    "    sn_keywords = import_keyword_list(input_sn_keywords) # school name\n",
    "    lt_keywords = import_keyword_list(input_lt_keywords) # location type\n",
    "    nh_keywords = import_keyword_list(input_nh_keywords) # neighborhood\n",
    "    \n",
    "    \n",
    "    # Output JSON Semantic Schema\n",
    "    jsonSchema = {\n",
    "        \"column_name\": \"\",\n",
    "        \"semantic_type\": [],\n",
    "        \"count\": 0\n",
    "    }\n",
    "\n",
    "    # Inner semantic schema \n",
    "    semanticSchema = {\n",
    "        \"semantic_type\": \"\",\n",
    "        \"label\": \"\",\n",
    "        \"count\": 0 \n",
    "    }\n",
    "\n",
    "    # Importing cluster3 format it and put it into a list\n",
    "    #raw_data = sc.textFile(\"/user/aj2885/Project_Resource/cluster3_labels.tsv\")\n",
    "    raw_data = sc.textFile(\"true_labels.tsv\")\n",
    "    raw_list = raw_data.map(lambda x: x.split(\"\\t\")).collect()\n",
    "\n",
    "    # Iteration over dataframes begins bu using dataframe file names\n",
    "    processCount = 1\n",
    "\n",
    "    # Create schema for raw data before reading into df \n",
    "    customSchema = StructType([\n",
    "                StructField(\"val\", StringType(), True),\n",
    "                StructField(\"count\", IntegerType(), True)])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Dataset =========== :  1 - vw9i-7mzq.interest3.txt.gz\n",
      "0.2676056338028169\n",
      "0.04225352112676056\n",
      "[['vw9i-7mzq.interest3.txt.gz', 0.29444444444444445, 0.3207935422230724, 71, 16.88888888888889, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2676056338028169, 0.04225352112676056, 0, [], 22]]\n",
      "Saving Dataset =============== :  1 - vw9i-7mzq.interest3.txt.gz\n",
      "Processing Dataset =========== :  2 - tyfh-9h2y.BROOKLYN___COOPERATIVES_COMPARABLE_PROPERTIES___Building_Classification.txt.gz\n",
      "[['tyfh-9h2y.BROOKLYN___COOPERATIVES_COMPARABLE_PROPERTIES___Building_Classification.txt.gz', 0.3785, 0.47786016085601163, 958, 10.5, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 958]]\n",
      "Saving Dataset =============== :  2 - tyfh-9h2y.BROOKLYN___COOPERATIVES_COMPARABLE_PROPERTIES___Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  3 - w7w3-xahh.Location.txt.gz\n",
      "[['w7w3-xahh.Location.txt.gz', 8.022479922576566e-05, 0.00413211825588574, 119500, 39.050562847004095, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['lat_lon_cord'], 119500]]\n",
      "Saving Dataset =============== :  3 - w7w3-xahh.Location.txt.gz\n",
      "Processing Dataset =========== :  4 - nfkx-wd79.Address_1.txt.gz\n",
      "[['nfkx-wd79.Address_1.txt.gz', 0.014797507788161994, 0.08923417616800781, 1983, 18.692107995846314, 0, 0, 0, 0, 0, 0.880988401412002, 0.011598587997982855, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['address'], 1770]]\n",
      "Saving Dataset =============== :  4 - nfkx-wd79.Address_1.txt.gz\n",
      "Processing Dataset =========== :  5 - uq7m-95z8.interest1.txt.gz\n",
      "0.117096018735363\n",
      "0.0117096018735363\n",
      "0.03044496487119438\n",
      "[['uq7m-95z8.interest1.txt.gz', 0.10222727272727271, 0.21056294880927037, 427, 17.454545454545453, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0117096018735363, 0, 0, 0, 0, 0, 0, 0, 0, 0.117096018735363, 0.03044496487119438, 0, [], 68]]\n",
      "Saving Dataset =============== :  5 - uq7m-95z8.interest1.txt.gz\n",
      "Processing Dataset =========== :  6 - a9md-ynri.MI.txt.gz\n",
      "0.06608911077099579\n",
      "[['a9md-ynri.MI.txt.gz', 0.24275, 0.24266355690925628, 798422, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06608911077099579, 0, 0, 0, 0, 0, 0, [], 52767]]\n",
      "Saving Dataset =============== :  6 - a9md-ynri.MI.txt.gz\n",
      "Processing Dataset =========== :  7 - s9d3-x4fz.EMPCITY.txt.gz\n",
      "0.24300839464252028\n",
      "0.2966893039049236\n",
      "0.24204159592529711\n",
      "[['s9d3-x4fz.EMPCITY.txt.gz', 0.0009195143884892062, 0.023071312640821996, 84816, 9.761690647482014, 0, 2.358045651763818e-05, 0, 0, 0, 0.0011436521411054518, 8.253159781173364e-05, 0, 0, 0, 0, 0, 0, 0, 0, 0.2966893039049236, 0, 0, 0, 0, 0, 0.24204159592529711, ['city agency', 'neighborhood', 'parks and playgrounds'], 66410]]\n",
      "Saving Dataset =============== :  7 - s9d3-x4fz.EMPCITY.txt.gz\n",
      "Processing Dataset =========== :  8 - kz72-dump.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "0.5283018867924528\n",
      "0.2641509433962264\n",
      "0.39622641509433965\n",
      "0.1320754716981132\n",
      "[['kz72-dump.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz', 0.2, 0.447213595499958, 53, 6.6, 0, 0, 0, 0, 0, 0.1320754716981132, 0, 0, 0, 0, 0.39622641509433965, 0, 0, 0, 0, 0, 0, 0, 0, 0.2641509433962264, 0, 0.1320754716981132, ['school subject', 'parks and playgrounds'], 49]]\n",
      "Saving Dataset =============== :  8 - kz72-dump.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  9 - 4pt5-3vv4.Location.txt.gz\n",
      "[['4pt5-3vv4.Location.txt.gz', 0.016190226650953436, 0.03395928258020093, 767156, 39.05257349450258, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['lat_lon_cord'], 767156]]\n",
      "Saving Dataset =============== :  9 - 4pt5-3vv4.Location.txt.gz\n",
      "Processing Dataset =========== :  10 - w9ak-ipjd.Applicant_Last_Name.txt.gz\n",
      "0.0008099297385951769\n",
      "2.024824346487942e-05\n",
      "0.00040496486929758846\n",
      "0.000911170955919574\n",
      "0.00046570959969222667\n",
      "[['w9ak-ipjd.Applicant_Last_Name.txt.gz', 0.005681902123730355, 0.03735364870870977, 49387, 6.852262234533702, 0, 0, 0, 0, 0, 0, 2.024824346487942e-05, 0, 0, 0, 0, 0, 0, 0, 0, 0.000911170955919574, 0, 0, 0, 0.0008099297385951769, 0.00040496486929758846, 0.00046570959969222667, [], 130]]\n",
      "Saving Dataset =============== :  10 - w9ak-ipjd.Applicant_Last_Name.txt.gz\n",
      "Processing Dataset =========== :  11 - 6anw-twe4.LastName.txt.gz\n",
      "9.888262632255513e-05\n",
      "0.0051418965687728664\n",
      "0.0005932957579353308\n",
      "[['6anw-twe4.LastName.txt.gz', 0.01864141791044769, 0.04920405062051493, 10113, 7.048880597014925, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0051418965687728664, 0, 0, 0, 0, 9.888262632255513e-05, 0.0005932957579353308, [], 59]]\n",
      "Saving Dataset =============== :  11 - 6anw-twe4.LastName.txt.gz\n",
      "Processing Dataset =========== :  12 - jz4z-kudi.Violation_Location__Zip_Code_.txt.gz\n",
      "1.3134953503578092e-07\n",
      "7.880972102146855e-07\n",
      "1.3134953503578092e-07\n",
      "[['jz4z-kudi.Violation_Location__Zip_Code_.txt.gz', 0.0012095788367873198, 0.016507462151836075, 15226548, 7.583564129500525, 0, 0.9948901747132706, 0, 0, 0, 0, 0, 3.953621004577006e-05, 0, 0, 0, 0, 0, 0, 0, 7.880972102146855e-07, 0, 0, 0, 0, 0, 1.3134953503578092e-07, ['zip_code'], 15149361]]\n",
      "Saving Dataset =============== :  12 - jz4z-kudi.Violation_Location__Zip_Code_.txt.gz\n",
      "Processing Dataset =========== :  13 - bdjm-n7q4.CrossStreet2.txt.gz\n",
      "5.952581733907692e-06\n",
      "[['bdjm-n7q4.CrossStreet2.txt.gz', 0.005677315054319716, 0.019348387422617824, 503983, 14.314407656492499, 0, 0, 0, 0, 0, 0.8418895081778552, 0.007549857832506255, 0, 0, 0, 0, 0, 0, 0, 0, 5.952581733907692e-06, 0, 0, 0, 0, 0, 0, ['street'], 428106]]\n",
      "Saving Dataset =============== :  13 - bdjm-n7q4.CrossStreet2.txt.gz\n",
      "Processing Dataset =========== :  14 - 6ypq-ih9a.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "0.5883153261304522\n",
      "0.2920368147258904\n",
      "0.4416966786714686\n",
      "0.14501800720288116\n",
      "[['6ypq-ih9a.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz', 0.2062, 0.4437895897832665, 12495, 6.6, 0, 0, 0, 0, 0, 0.1466186474589836, 0, 0, 0, 0, 0.4416966786714686, 0, 0, 0, 0, 0, 0, 0, 0, 0.2920368147258904, 0, 0.14501800720288116, ['school subject', 'school subject', 'parks and playgrounds'], 12812]]\n",
      "Saving Dataset =============== :  14 - 6ypq-ih9a.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  15 - aiww-p3af.Incident_Zip.txt.gz\n",
      "5.726484762969343e-07\n",
      "[['aiww-p3af.Incident_Zip.txt.gz', 0.05882271147161068, 0.14345136638733513, 1746272, 5.93279258400927, 0, 0.999749179967382, 0, 5.726484762969343e-07, 0, 0, 0, 5.153836286672408e-06, 0, 0, 0, 0, 0, 0, 0, 5.726484762969343e-07, 0, 0, 0, 0, 0, 0, ['zip_code'], 1745845]]\n",
      "Saving Dataset =============== :  15 - aiww-p3af.Incident_Zip.txt.gz\n",
      "Processing Dataset =========== :  16 - sxmw-f24h.Cross_Street_2.txt.gz\n",
      "3.412240251741437e-06\n",
      "4.094688302089725e-06\n",
      "4.026443497054895e-05\n",
      "8.18937660417945e-06\n",
      "[['sxmw-f24h.Cross_Street_2.txt.gz', 0.005372097145896044, 0.02469110279505955, 1465313, 12.829906045027478, 0, 0, 0, 0, 0, 0.8609484799493351, 0.008538790005957772, 1.0236720755224311e-05, 0, 0, 0, 0, 0, 0, 0, 4.026443497054895e-05, 0, 0, 0, 0, 4.094688302089725e-06, 8.18937660417945e-06, ['street'], 1274168]]\n",
      "Saving Dataset =============== :  16 - sxmw-f24h.Cross_Street_2.txt.gz\n",
      "Processing Dataset =========== :  17 - f7qh-bcr5.CORE_SUBJECT___MS_CORE_and__9_12_ONLY_.txt.gz\n",
      "0.7687074829931972\n",
      "0.43537414965986393\n",
      "0.5782312925170068\n",
      "0.21768707482993196\n",
      "[['f7qh-bcr5.CORE_SUBJECT___MS_CORE_and__9_12_ONLY_.txt.gz', 0.6460000000000001, 0.3982135105693929, 147, 6.6, 0, 0, 0, 0, 0, 0.19047619047619047, 0, 0, 0, 0, 0.5782312925170068, 0, 0, 0, 0, 0, 0, 0, 0, 0.43537414965986393, 0, 0.21768707482993196, ['school subject', 'area of study', 'school subject', 'parks and playgrounds'], 209]]\n",
      "Saving Dataset =============== :  17 - f7qh-bcr5.CORE_SUBJECT___MS_CORE_and__9_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  18 - w7w3-xahh.Address_City.txt.gz\n",
      "0.371872651809714\n",
      "0.47142835529600435\n",
      "0.37183230706386067\n",
      "[['w7w3-xahh.Address_City.txt.gz', 0.0014847784200385263, 0.02695191289343131, 198291, 9.845472061657032, 0, 0, 0, 0, 0, 0.004589214840814762, 0.002924994074365453, 0, 0, 0, 0, 0, 0, 0, 0, 0.47142835529600435, 0, 0, 0, 0, 0, 0.37183230706386067, ['city agency', 'neighborhood', 'parks and playgrounds'], 242440]]\n",
      "Saving Dataset =============== :  18 - w7w3-xahh.Address_City.txt.gz\n",
      "Processing Dataset =========== :  19 - p2d7-vcsb.ACCOUNT_CITY.txt.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28636006289308175\n",
      "0.34394654088050314\n",
      "0.2456761006289308\n",
      "[['p2d7-vcsb.ACCOUNT_CITY.txt.gz', 0.01819801980198018, 0.07556178382538213, 5088, 9.58085808580858, 0, 0, 0, 0, 0, 0.005699685534591195, 0.00039308176100628933, 0, 0, 0, 0, 0, 0, 0, 0, 0.34394654088050314, 0, 0, 0, 0, 0, 0.2456761006289308, ['city agency', 'neighborhood', 'parks and playgrounds'], 4488]]\n",
      "Saving Dataset =============== :  19 - p2d7-vcsb.ACCOUNT_CITY.txt.gz\n",
      "Processing Dataset =========== :  20 - qcdj-rwhu.BUSINESS_NAME2.txt.gz\n",
      "[['qcdj-rwhu.BUSINESS_NAME2.txt.gz', 0.008068647540983607, 0.052338488074875206, 1039, 13.487704918032787, 0, 0, 0, 0, 0, 0.03176130895091434, 0.007699711260827719, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 41]]\n",
      "Saving Dataset =============== :  20 - qcdj-rwhu.BUSINESS_NAME2.txt.gz\n",
      "Processing Dataset =========== :  21 - kj4p-ruqc.StreetName.txt.gz\n",
      "3.050463823024291e-06\n",
      "3.660556587629149e-05\n",
      "3.050463823024291e-06\n",
      "[['kj4p-ruqc.StreetName.txt.gz', 0.025680065524193614, 0.060833814228135275, 327819, 13.018397177419354, 0, 3.050463823024291e-06, 0, 0, 0, 0.9247999658348052, 0.005853840076383614, 1.5252319115121454e-05, 0, 0, 0, 0, 0, 0, 0, 3.660556587629149e-05, 0, 0, 0, 0, 0, 3.050463823024291e-06, ['street'], 305106]]\n",
      "Saving Dataset =============== :  21 - kj4p-ruqc.StreetName.txt.gz\n",
      "Processing Dataset =========== :  22 - sxx4-xhzg.Park_Site_Name.txt.gz\n",
      "[['sxx4-xhzg.Park_Site_Name.txt.gz', 0.03923268698060941, 0.11151629744239214, 545, 18.390581717451525, 0, 0, 0, 0, 0, 0.10642201834862386, 0.01834862385321101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 68]]\n",
      "Saving Dataset =============== :  22 - sxx4-xhzg.Park_Site_Name.txt.gz\n",
      "Processing Dataset =========== :  23 - 6je4-4x7e.SCHOOL_LEVEL_.txt.gz\n",
      "[['6je4-4x7e.SCHOOL_LEVEL_.txt.gz', 0.31477777777777777, 0.37640097561569164, 1817, 7.0, 0, 0, 0, 0, 0, 0, 0.28673637864612, 0, 0.9686296092460099, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['school level'], 2281]]\n",
      "Saving Dataset =============== :  23 - 6je4-4x7e.SCHOOL_LEVEL_.txt.gz\n",
      "Processing Dataset =========== :  24 - yayv-apxh.SCHOOL_LEVEL_.txt.gz\n",
      "[['yayv-apxh.SCHOOL_LEVEL_.txt.gz', 0.4732, 0.3897328572240221, 1493, 11.8, 0, 0, 0, 0, 0, 0, 0.9055592766242465, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['school_name', 'school level'], 2845]]\n",
      "Saving Dataset =============== :  24 - yayv-apxh.SCHOOL_LEVEL_.txt.gz\n",
      "Processing Dataset =========== :  25 - 5uac-w243.PREM_TYP_DESC.txt.gz\n",
      "0.0070937998112534486\n",
      "0.3461060863989596\n",
      "0.27089194034164027\n",
      "[['5uac-w243.PREM_TYP_DESC.txt.gz', 0.049878378378378385, 0.15731862378343878, 221461, 14.5, 0, 0, 0, 0, 0, 0.07968445911469739, 0.011604752078244025, 0, 0, 0, 0, 0, 0, 0, 0, 0.27089194034164027, 0, 0, 0, 0, 0.3461060863989596, 0, ['location type', 'neighborhood'], 158429]]\n",
      "Saving Dataset =============== :  25 - 5uac-w243.PREM_TYP_DESC.txt.gz\n",
      "Processing Dataset =========== :  26 - uzcy-9puk.School_Phone_Number.txt.gz\n",
      "[['uzcy-9puk.School_Phone_Number.txt.gz', 0.0006855775803144223, 0.026144334795896697, 1874697, 9.997949419002051, 0, 0, 0, 0.008000759589416316, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 14999]]\n",
      "Saving Dataset =============== :  26 - uzcy-9puk.School_Phone_Number.txt.gz\n",
      "Processing Dataset =========== :  27 - 2sps-j9st.PERSON_LAST_NAME.txt.gz\n",
      "0.00015413367242741267\n",
      "0.00017340038148083925\n",
      "0.00015413367242741267\n",
      "0.0004816677263356646\n",
      "0.000558734562549371\n",
      "0.006531414369111612\n",
      "0.0023505385045180433\n",
      "[['2sps-j9st.PERSON_LAST_NAME.txt.gz', 0.007694210441594839, 0.025571394931601644, 51903, 7.74969147394967, 1.9266709053426584e-05, 0, 1.9266709053426584e-05, 0, 0, 0.00078993507119049, 0.0007706683621370634, 0, 0, 0, 0.00015413367242741267, 0, 0, 0, 0, 0.006531414369111612, 0, 0, 0, 0.00017340038148083925, 0.000558734562549371, 0.0023505385045180433, [], 615]]\n",
      "Saving Dataset =============== :  27 - 2sps-j9st.PERSON_LAST_NAME.txt.gz\n",
      "Processing Dataset =========== :  28 - mrxb-9w9v.BOROUGH___COMMUNITY.txt.gz\n",
      "0.7589285714285714\n",
      "0.7767857142857143\n",
      "0.9285714285714286\n",
      "[['mrxb-9w9v.BOROUGH___COMMUNITY.txt.gz', 0.4206666666666667, 0.3504081429799636, 112, 8.166666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7767857142857143, 0, 0, 0, 0, 0, 0.9285714285714286, ['city agency', 'neighborhood', 'parks and playgrounds'], 276]]\n",
      "Saving Dataset =============== :  28 - mrxb-9w9v.BOROUGH___COMMUNITY.txt.gz\n",
      "Processing Dataset =========== :  29 - 7crd-d9xh.website.txt.gz\n",
      "[['7crd-d9xh.website.txt.gz', 0.004597701149425287, 0.06772818739620157, 437, 27.041379310344826, 0.9977116704805492, 0, 0, 0, 0, 0, 0.05491990846681922, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['website'], 460]]\n",
      "Saving Dataset =============== :  29 - 7crd-d9xh.website.txt.gz\n",
      "Processing Dataset =========== :  30 - 29bw-z7pj.Location_1.txt.gz\n",
      "[['29bw-z7pj.Location_1.txt.gz', 7.588463059259155e-05, 0.001959105935250286, 592372, 26.777508784756677, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['lat_lon_cord'], 592372]]\n",
      "Saving Dataset =============== :  30 - 29bw-z7pj.Location_1.txt.gz\n",
      "Processing Dataset =========== :  31 - p937-wjvj.HOUSE_NUMBER.txt.gz\n",
      "[['p937-wjvj.HOUSE_NUMBER.txt.gz', 0.007365634463222128, 0.02607914984018581, 1742862, 4.886484638304108, 0, 0.0004894248655372599, 0, 1.1475377855504338e-05, 0, 8.032764498853036e-06, 0, 0.889850143040585, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['house number'], 1551773]]\n",
      "Saving Dataset =============== :  31 - p937-wjvj.HOUSE_NUMBER.txt.gz\n",
      "Processing Dataset =========== :  32 - h9gi-nx95.VEHICLE_TYPE_CODE_2.txt.gz\n",
      "6.019717240927372e-05\n",
      "0.05331793098508482\n",
      "6.095916193344174e-06\n",
      "0.02037636186577707\n",
      "[['h9gi-nx95.VEHICLE_TYPE_CODE_2.txt.gz', 0.005146186440677965, 0.05241138336702244, 1312354, 5.2690677966101696, 0, 7.619895241680218e-07, 7.619895241680218e-07, 0, 0, 0.18171773774454147, 0.00016992366388946884, 2.2859685725040652e-06, 0, 0, 0, 0, 0, 0, 0, 6.095916193344174e-06, 0, 0, 0, 0, 0.05331793098508482, 0.02037636186577707, [], 335506]]\n",
      "Saving Dataset =============== :  32 - h9gi-nx95.VEHICLE_TYPE_CODE_2.txt.gz\n",
      "Processing Dataset =========== :  33 - qu8g-sxqf.MI.txt.gz\n",
      "0.07032621868275914\n",
      "[['qu8g-sxqf.MI.txt.gz', 0.24628571428571427, 0.258149950271924, 161732, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07032621868275914, 0, 0, 0, 0, 0, 0, [], 11374]]\n",
      "Saving Dataset =============== :  33 - qu8g-sxqf.MI.txt.gz\n",
      "Processing Dataset =========== :  34 - 2bnn-yakx.Vehicle_Body_Type.txt.gz\n",
      "9.293392685895502e-08\n",
      "4.646696342947751e-07\n",
      "0.009979802669675743\n",
      "3.903224928076111e-06\n",
      "0.13122214712128333\n",
      "[['2bnn-yakx.Vehicle_Body_Type.txt.gz', 0.001559221200648998, 0.0319682757152618, 10760333, 3.417522985397512, 0, 0, 0, 0, 0, 0.005424181575049768, 0, 2.9738856594865605e-06, 0, 0, 9.293392685895502e-08, 0, 0, 0, 0, 3.903224928076111e-06, 0, 0, 0, 0, 0.009979802669675743, 0.13122214712128333, ['parks and playgrounds'], 1577826]]\n",
      "Saving Dataset =============== :  34 - 2bnn-yakx.Vehicle_Body_Type.txt.gz\n",
      "Processing Dataset =========== :  35 - mqdy-gu73.Color.txt.gz\n",
      "0.046413502109704644\n",
      "[['mqdy-gu73.Color.txt.gz', 0.16907407407407404, 0.23223279532630878, 237, 9.11111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.046413502109704644, 0, 0, 0, 0, 0, 0, [], 11]]\n",
      "Saving Dataset =============== :  35 - mqdy-gu73.Color.txt.gz\n",
      "Processing Dataset =========== :  36 - 3rfa-3xsf.Intersection_Street_2.txt.gz\n",
      "0.00014476257518428843\n",
      "5.676963732717193e-06\n",
      "0.00025546336797227374\n",
      "0.00022707854930868775\n",
      "[['3rfa-3xsf.Intersection_Street_2.txt.gz', 0.0038690150970524403, 0.015951485117503588, 352301, 12.685765636232926, 0, 0, 0, 2.8384818663585966e-06, 0, 0.8641133576118148, 0.009091657417946585, 3.406178239630316e-05, 0, 0, 0, 0, 0, 0, 0, 0.00025546336797227374, 0, 0, 0, 0, 5.676963732717193e-06, 0.00022707854930868775, ['street'], 307867]]\n",
      "Saving Dataset =============== :  36 - 3rfa-3xsf.Intersection_Street_2.txt.gz\n",
      "Processing Dataset =========== :  37 - 7btz-mnc8.Provider_First_Name.txt.gz\n",
      "0.02021772939346812\n",
      "[['7btz-mnc8.Provider_First_Name.txt.gz', 0.022656000000000058, 0.07418824691812463, 1929, 6.384, 0, 0, 0, 0, 0, 0, 0.002592016588906169, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.02021772939346812, [], 44]]\n",
      "Saving Dataset =============== :  37 - 7btz-mnc8.Provider_First_Name.txt.gz\n",
      "Processing Dataset =========== :  38 - wg9x-4ke6.Principal_phone_number.txt.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['wg9x-4ke6.Principal_phone_number.txt.gz', 0.001086760280842527, 0.02255314279897806, 2190, 11.995987963891675, 0, 0, 0, 0.9584474885844749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['phone_number'], 2099]]\n",
      "Saving Dataset =============== :  38 - wg9x-4ke6.Principal_phone_number.txt.gz\n",
      "Processing Dataset =========== :  39 - cyfw-hfqk.STATEN_ISLAND_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz\n",
      "0.25\n",
      "[['cyfw-hfqk.STATEN_ISLAND_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz', 0.15155555555555555, 0.32460826819071903, 24, 12.11111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25, 0, 0, 0, 0, 0, 0, ['neighborhood'], 6]]\n",
      "Saving Dataset =============== :  39 - cyfw-hfqk.STATEN_ISLAND_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz\n",
      "Processing Dataset =========== :  40 - sqcr-6mww.Cross_Street_1.txt.gz\n",
      "7.506404571614853e-06\n",
      "1.0723435102306932e-06\n",
      "[['sqcr-6mww.Cross_Street_1.txt.gz', 0.006666392769104305, 0.029173850509321152, 932537, 12.995891536565324, 0, 0, 0, 0, 0, 0.8668224424339195, 0.008757829448054071, 5.361717551153466e-06, 0, 0, 0, 0, 0, 0, 0, 7.506404571614853e-06, 0, 0, 0, 0, 0, 1.0723435102306932e-06, ['street'], 816524]]\n",
      "Saving Dataset =============== :  40 - sqcr-6mww.Cross_Street_1.txt.gz\n",
      "Processing Dataset =========== :  41 - 72ss-25qh.Agency_ID.txt.gz\n",
      "0.00667779632721202\n",
      "[['72ss-25qh.Agency_ID.txt.gz', 0.033297297297297294, 0.10049326488802182, 599, 28.513513513513512, 0, 0, 0, 0, 0, 0.06343906510851419, 0.03171953255425709, 0, 0, 0, 0, 0, 0, 0, 0, 0.00667779632721202, 0, 0, 0, 0, 0, 0, [], 61]]\n",
      "Saving Dataset =============== :  41 - 72ss-25qh.Agency_ID.txt.gz\n",
      "Processing Dataset =========== :  42 - s3zn-tf7c.QUEENS_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz\n",
      "[['s3zn-tf7c.QUEENS_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz', 0.4066666666666667, 0.5254839039716948, 353, 10.333333333333334, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 353]]\n",
      "Saving Dataset =============== :  42 - s3zn-tf7c.QUEENS_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  43 - qgea-i56i.Lat_Lon.txt.gz\n",
      "[['qgea-i56i.Lat_Lon.txt.gz', 0.0026217363855711644, 0.008365712364712018, 6483531, 28.776418088574864, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['lat_lon_cord'], 6483531]]\n",
      "Saving Dataset =============== :  43 - qgea-i56i.Lat_Lon.txt.gz\n",
      "Processing Dataset =========== :  44 - i6b5-j7bu.TOSTREETNAME.txt.gz\n",
      "[['i6b5-j7bu.TOSTREETNAME.txt.gz', 0.012644325767690328, 0.041885458388862394, 65133, 13.971428571428572, 0, 0, 0, 0, 0, 0.7786068505980072, 0.007584480985061336, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 51207]]\n",
      "Saving Dataset =============== :  44 - i6b5-j7bu.TOSTREETNAME.txt.gz\n",
      "Processing Dataset =========== :  45 - uzcy-9puk.Location.txt.gz\n",
      "[['uzcy-9puk.Location.txt.gz', 0.002823318741495196, 0.010091097025797116, 1737800, 34.77817019976977, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['lat_lon_cord'], 1737800]]\n",
      "Saving Dataset =============== :  45 - uzcy-9puk.Location.txt.gz\n",
      "Processing Dataset =========== :  46 - vrn4-2abs.SCHOOL_LEVEL_.txt.gz\n",
      "[['vrn4-2abs.SCHOOL_LEVEL_.txt.gz', 0.4779999999999999, 0.3948411072824105, 1543, 9.0, 0, 0, 0, 0, 0, 0, 0.2825664290343487, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['school level'], 1979]]\n",
      "Saving Dataset =============== :  46 - vrn4-2abs.SCHOOL_LEVEL_.txt.gz\n",
      "Processing Dataset =========== :  47 - irhv-jqz7.BROOKLYN___COOPERATIVES_COMPARABLE_PROPERTIES___Building_Classification.txt.gz\n",
      "[['irhv-jqz7.BROOKLYN___COOPERATIVES_COMPARABLE_PROPERTIES___Building_Classification.txt.gz', 0.34099999999999997, 0.4716538278582433, 514, 10.5, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 514]]\n",
      "Saving Dataset =============== :  47 - irhv-jqz7.BROOKLYN___COOPERATIVES_COMPARABLE_PROPERTIES___Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  48 - m56g-jpua.COMPARABLE_RENTAL___1___Building_Classification.txt.gz\n",
      "[['m56g-jpua.COMPARABLE_RENTAL___1___Building_Classification.txt.gz', 0.38975000000000004, 0.3103119032082515, 2261, 10.666666666666666, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 2261]]\n",
      "Saving Dataset =============== :  48 - m56g-jpua.COMPARABLE_RENTAL___1___Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  49 - ajxm-kzmj.NeighborhoodName.txt.gz\n",
      "0.12074303405572756\n",
      "[['ajxm-kzmj.NeighborhoodName.txt.gz', 0.08845454545454542, 0.19080591684247608, 323, 12.075757575757576, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.12074303405572756, 0, 0, 0, 0, 0, 0, ['neighborhood'], 39]]\n",
      "Saving Dataset =============== :  49 - ajxm-kzmj.NeighborhoodName.txt.gz\n",
      "Processing Dataset =========== :  50 - w7w3-xahh.Address_ZIP.txt.gz\n",
      "5.04375457090258e-06\n",
      "5.04375457090258e-06\n",
      "5.04375457090258e-06\n",
      "[['w7w3-xahh.Address_ZIP.txt.gz', 0.02150028058361423, 0.09364430556097085, 198265, 4.989618406285073, 0, 0.9994199682243462, 0, 0, 0, 0, 0, 0.0003026252742541548, 0, 0, 0, 0, 0, 0, 0, 5.04375457090258e-06, 0, 0, 0, 0, 0, 5.04375457090258e-06, ['zip_code'], 198213]]\n",
      "Saving Dataset =============== :  50 - w7w3-xahh.Address_ZIP.txt.gz\n",
      "Processing Dataset =========== :  51 - 5694-9szk.Business_Website_or_Other_URL.txt.gz\n",
      "[['5694-9szk.Business_Website_or_Other_URL.txt.gz', 0.006258692628650904, 0.049833904822194255, 1474, 32.012517385257304, 0.9972862957937585, 0, 0, 0, 0, 0.0006784260515603799, 0.006105834464043419, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['website'], 1480]]\n",
      "Saving Dataset =============== :  51 - 5694-9szk.Business_Website_or_Other_URL.txt.gz\n",
      "Processing Dataset =========== :  52 - 6bgk-3dad.RESPONDENT_ZIP.txt.gz\n",
      "2.7362401324340225e-05\n",
      "[['6bgk-3dad.RESPONDENT_ZIP.txt.gz', 0.0057580809107541705, 0.047036728420792845, 1242581, 6.756149623907298, 0, 0.994202390025278, 8.047765095394183e-07, 0, 0, 1.6095530190788367e-06, 0, 0.0004941327768572029, 0, 0, 0, 0, 0, 0, 0, 2.7362401324340225e-05, 0, 0, 0, 0, 0, 0, ['zip_code'], 1236028]]\n",
      "Saving Dataset =============== :  52 - 6bgk-3dad.RESPONDENT_ZIP.txt.gz\n",
      "Processing Dataset =========== :  53 - en2c-j6tw.BRONX_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz\n",
      "[['en2c-j6tw.BRONX_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz', 0.5236666666666666, 0.5016775192624574, 48, 10.333333333333334, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 48]]\n",
      "Saving Dataset =============== :  53 - en2c-j6tw.BRONX_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  54 - 3rfa-3xsf.Street_Name.txt.gz\n",
      "1.4277688185284415e-06\n",
      "1.1422150548227532e-05\n",
      "1.6419341413077076e-05\n",
      "7.138844092642207e-07\n",
      "[['3rfa-3xsf.Street_Name.txt.gz', 0.005595771812080654, 0.0221564710847312, 1400787, 13.117114093959731, 0, 6.282182801525143e-05, 0, 0, 0, 0.8822262056972259, 0.009477529417391795, 0.0001242158872119744, 0, 0, 0, 0, 0, 0, 0, 1.6419341413077076e-05, 0, 0, 0, 0, 1.1422150548227532e-05, 7.138844092642207e-07, ['street'], 1249391]]\n",
      "Saving Dataset =============== :  54 - 3rfa-3xsf.Street_Name.txt.gz\n",
      "Processing Dataset =========== :  55 - mmvm-mvi3.Org_Name.txt.gz\n",
      "[['mmvm-mvi3.Org_Name.txt.gz', 0.22212507237984927, 0.12821192304128945, 11702, 23.070063694267517, 0, 0, 0, 0, 0, 0.0584515467441463, 0.35925482823448984, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 4888]]\n",
      "Saving Dataset =============== :  55 - mmvm-mvi3.Org_Name.txt.gz\n",
      "Processing Dataset =========== :  56 - erm2-nwe9.Landmark.txt.gz\n",
      "3.21447284252619e-06\n",
      "1.928683705515714e-05\n",
      "1.607236421263095e-05\n",
      "[['erm2-nwe9.Landmark.txt.gz', 0.011995778292251316, 0.03143823178040529, 311093, 14.027781560670025, 0, 0, 0, 0, 0, 0.8623241281546032, 0.006265007570083544, 0, 0, 0, 0, 0, 0, 0, 0, 1.928683705515714e-05, 0, 0, 0, 0, 0, 1.607236421263095e-05, ['street'], 270224]]\n",
      "Saving Dataset =============== :  56 - erm2-nwe9.Landmark.txt.gz\n",
      "Processing Dataset =========== :  57 - dvzp-h4k9.COMPARABLE_RENTAL_____1_____Building_Classification.txt.gz\n",
      "[['dvzp-h4k9.COMPARABLE_RENTAL_____1_____Building_Classification.txt.gz', 0.3453333333333333, 0.35017277121011237, 1381, 10.666666666666666, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 1381]]\n",
      "Saving Dataset =============== :  57 - dvzp-h4k9.COMPARABLE_RENTAL_____1_____Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  58 - i8ys-e4pm.CORE_COURSE_9_12_ONLY_.txt.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18827611395178961\n",
      "0.06525444363282201\n",
      "[['i8ys-e4pm.CORE_COURSE_9_12_ONLY_.txt.gz', 0.08264999999999999, 0.21670821396523024, 16428, 10.45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06525444363282201, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 1072]]\n",
      "Saving Dataset =============== :  58 - i8ys-e4pm.CORE_COURSE_9_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  59 - jt7v-77mi.Vehicle_Make.txt.gz\n",
      "1.1065493001462969e-07\n",
      "7.745845101024079e-07\n",
      "6.639295800877781e-07\n",
      "0.0001751667542131588\n",
      "3.9614464945237425e-05\n",
      "4.4704591725910394e-05\n",
      "[['jt7v-77mi.Vehicle_Make.txt.gz', 0.0010480139676996949, 0.02121762121099167, 9037103, 4.34730103302779, 0, 8.852394401170375e-07, 1.1065493001462969e-07, 0, 0, 6.639295800877781e-07, 2.766373250365742e-06, 5.090126780672966e-06, 0, 0, 7.745845101024079e-07, 0, 0, 0, 0, 3.9614464945237425e-05, 0, 0, 0, 1.1065493001462969e-07, 0.0001751667542131588, 4.4704591725910394e-05, [], 2445]]\n",
      "Saving Dataset =============== :  59 - jt7v-77mi.Vehicle_Make.txt.gz\n",
      "Processing Dataset =========== :  60 - t8hj-ruu2.First_Name.txt.gz\n",
      "1.1868872694471479e-05\n",
      "9.495098155577183e-05\n",
      "4.7475490777885916e-05\n",
      "0.0022194791938661665\n",
      "0.08309397773399482\n",
      "[['t8hj-ruu2.First_Name.txt.gz', 0.0020073082607982014, 0.020943575478606872, 84254, 6.461323698472656, 0, 0, 0, 0, 0, 0, 7.121323616682887e-05, 0, 0, 0, 0, 0, 0, 0, 0, 0.0022194791938661665, 0, 0, 0, 1.1868872694471479e-05, 4.7475490777885916e-05, 0.08309397773399482, [], 7207]]\n",
      "Saving Dataset =============== :  60 - t8hj-ruu2.First_Name.txt.gz\n",
      "Processing Dataset =========== :  61 - qu8g-sxqf.First_Name.txt.gz\n",
      "1.2426476679645432e-05\n",
      "1.2426476679645432e-05\n",
      "0.00026095601027255403\n",
      "4.5563747825366584e-05\n",
      "0.0003893629359622235\n",
      "0.03453317869273465\n",
      "[['qu8g-sxqf.First_Name.txt.gz', 0.0009764318378050319, 0.0117407770963635, 241420, 6.681270186434716, 0, 0, 0, 0, 0, 1.6568635572860574e-05, 2.0710794466075717e-05, 0, 0, 0, 1.2426476679645432e-05, 0, 0, 0, 0, 0.0003893629359622235, 0, 0, 0, 0, 4.5563747825366584e-05, 0.03453317869273465, [], 8517]]\n",
      "Saving Dataset =============== :  61 - qu8g-sxqf.First_Name.txt.gz\n",
      "Processing Dataset =========== :  62 - ci93-uc8s.ZIP.txt.gz\n",
      "[['ci93-uc8s.ZIP.txt.gz', 0.02882173295454563, 0.0720702603514777, 9372, 5.002840909090909, 0, 0.9985061886470337, 0, 0, 0, 0, 0, 0.0011737089201877935, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['zip_code'], 9369]]\n",
      "Saving Dataset =============== :  62 - ci93-uc8s.ZIP.txt.gz\n",
      "Processing Dataset =========== :  63 - uh2w-zjsn.Borough.txt.gz\n",
      "0.6\n",
      "0.6\n",
      "0.8\n",
      "[['uh2w-zjsn.Borough.txt.gz', 0.5, 0.0, 25, 8.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6, 0, 0, 0, 0, 0, 0.8, ['city agency', 'neighborhood', 'parks and playgrounds'], 50]]\n",
      "Saving Dataset =============== :  63 - uh2w-zjsn.Borough.txt.gz\n",
      "Processing Dataset =========== :  64 - sv2w-rv3k.BORO.txt.gz\n",
      "0.6999773442297006\n",
      "0.7789665037999709\n",
      "0.963795258356772\n",
      "[['sv2w-rv3k.BORO.txt.gz', 0.5536666666666666, 0.41721393393158224, 4630167, 8.166666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7789665037999709, 0, 0, 0, 0, 0, 0.963795258356772, ['city agency', 'neighborhood', 'parks and playgrounds'], 11310290]]\n",
      "Saving Dataset =============== :  64 - sv2w-rv3k.BORO.txt.gz\n",
      "Processing Dataset =========== :  65 - crbs-vur7.QUEENS_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz\n",
      "0.17320261437908496\n",
      "[['crbs-vur7.QUEENS_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz', 0.08699999999999998, 0.182086892344387, 306, 11.176470588235293, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17320261437908496, 0, 0, 0, 0, 0, 0, ['neighborhood'], 53]]\n",
      "Saving Dataset =============== :  65 - crbs-vur7.QUEENS_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz\n",
      "Processing Dataset =========== :  66 - bty7-2jhb.Site_Safety_Mgr_s_Last_Name.txt.gz\n",
      "0.0008286529785470951\n",
      "0.0011048706380627936\n",
      "[['bty7-2jhb.Site_Safety_Mgr_s_Last_Name.txt.gz', 0.014999999999999986, 0.04083313189303721, 10861, 6.924818108326597, 0, 0, 0, 0, 0, 0, 0.00018414510634379893, 0.00018414510634379893, 0, 0, 0, 0, 0, 0, 0, 0.0008286529785470951, 0, 0, 0, 0, 0, 0.0011048706380627936, [], 25]]\n",
      "Saving Dataset =============== :  66 - bty7-2jhb.Site_Safety_Mgr_s_Last_Name.txt.gz\n",
      "Processing Dataset =========== :  67 - nyis-y4yr.Owner_s__Phone__.txt.gz\n",
      "[['nyis-y4yr.Owner_s__Phone__.txt.gz', 0.010777047744196539, 0.03696606014065881, 15284, 10.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['phone_number'], 15284]]\n",
      "Saving Dataset =============== :  67 - nyis-y4yr.Owner_s__Phone__.txt.gz\n",
      "Processing Dataset =========== :  68 - s3k6-pzi2.interest5.txt.gz\n",
      "0.34210526315789475\n",
      "0.02631578947368421\n",
      "[['s3k6-pzi2.interest5.txt.gz', 0.1903571428571429, 0.2593852516840709, 38, 16.428571428571427, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.34210526315789475, 0.02631578947368421, 0, ['area of study'], 14]]\n",
      "Saving Dataset =============== :  68 - s3k6-pzi2.interest5.txt.gz\n",
      "Processing Dataset =========== :  69 - ub9e-s7ai.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "0.5938459053464706\n",
      "0.2947827491519948\n",
      "0.44645453077047326\n",
      "0.14617993862057826\n",
      "[['ub9e-s7ai.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz', 0.20699999999999993, 0.44336835701254096, 12382, 6.6, 0, 0, 0, 0, 0, 0.1473913745759974, 0, 0, 0, 0, 0.44645453077047326, 0, 0, 0, 0, 0, 0, 0, 0, 0.2947827491519948, 0, 0.14617993862057826, ['school subject', 'school subject', 'parks and playgrounds'], 12813]]\n",
      "Saving Dataset =============== :  69 - ub9e-s7ai.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  70 - mdcw-n682.First_Name.txt.gz\n",
      "0.000612619971411068\n",
      "0.00020420665713702266\n",
      "0.00020420665713702266\n",
      "0.043496017970185825\n",
      "[['mdcw-n682.First_Name.txt.gz', 0.011838670694864079, 0.045315499703156216, 4897, 6.132930513595166, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00020420665713702266, 0, 0, 0, 0, 0.00020420665713702266, 0.043496017970185825, [], 218]]\n",
      "Saving Dataset =============== :  70 - mdcw-n682.First_Name.txt.gz\n",
      "Processing Dataset =========== :  71 - h9gi-nx95.VEHICLE_TYPE_CODE_1.txt.gz\n",
      "5.114131431899267e-05\n",
      "0.0544597463518663\n",
      "3.83559857392445e-06\n",
      "0.01871452470860638\n",
      "[['h9gi-nx95.VEHICLE_TYPE_CODE_1.txt.gz', 0.004541666666666666, 0.05131191543174819, 1564293, 5.275, 0, 6.392664289874084e-07, 0, 0, 0, 0.2009642694814846, 0.00014830981152507875, 6.392664289874084e-07, 0, 0, 0, 0, 0, 0, 0, 3.83559857392445e-06, 0, 0, 0, 0, 0.0544597463518663, 0.01871452470860638, [], 429153]]\n",
      "Saving Dataset =============== :  71 - h9gi-nx95.VEHICLE_TYPE_CODE_1.txt.gz\n",
      "Processing Dataset =========== :  72 - jz4z-kudi.Violation_Location__City_.txt.gz\n",
      "0.4592504566370668\n",
      "1.3486143324887261e-06\n",
      "0.538447308851338\n",
      "0.4826669717531979\n",
      "[['jz4z-kudi.Violation_Location__City_.txt.gz', 0.0003218438195761519, 0.013388844663970785, 13347033, 10.15543827822215, 1.4984603694319178e-07, 1.7981524433183016e-06, 0, 0, 0, 0.0009882346136403498, 7.260040489897642e-05, 1.498460369431918e-06, 0, 0, 0, 0, 0, 0, 0, 0.538447308851338, 0, 0, 0, 0, 1.3486143324887261e-06, 0.4826669717531979, ['city agency', 'neighborhood', 'parks and playgrounds'], 19772700]]\n",
      "Saving Dataset =============== :  72 - jz4z-kudi.Violation_Location__City_.txt.gz\n",
      "Processing Dataset =========== :  73 - erm2-nwe9.City.txt.gz\n",
      "0.5079114486451903\n",
      "0.594142635135402\n",
      "0.5079169283082355\n",
      "[['erm2-nwe9.City.txt.gz', 0.0012474103585657366, 0.026733762262464923, 20256720, 9.81792828685259, 0, 0, 0, 0, 0, 1.6883286139118277e-05, 1.4809900122033578e-07, 6.41762338621455e-07, 0, 0, 0, 0, 0, 0, 0, 0.594142635135402, 0, 0, 0, 0, 0, 0.5079169283082355, ['city agency', 'neighborhood', 'parks and playgrounds'], 32613090]]\n",
      "Saving Dataset =============== :  73 - erm2-nwe9.City.txt.gz\n",
      "Processing Dataset =========== :  74 - vw9i-7mzq.interest1.txt.gz\n",
      "0.11264367816091954\n",
      "0.009195402298850575\n",
      "0.027586206896551724\n",
      "[['vw9i-7mzq.interest1.txt.gz', 0.10420000000000003, 0.21858410401105516, 435, 16.35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.009195402298850575, 0, 0, 0, 0, 0, 0, 0, 0, 0.11264367816091954, 0.027586206896551724, 0, [], 65]]\n",
      "Saving Dataset =============== :  74 - vw9i-7mzq.interest1.txt.gz\n",
      "Processing Dataset =========== :  75 - bawj-6bgn.BRONX_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz\n",
      "0.4090909090909091\n",
      "[['bawj-6bgn.BRONX_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz', 0.1921764705882353, 0.28757417201787216, 66, 15.647058823529411, 0, 0, 0, 0, 0, 0, 0.030303030303030304, 0, 0, 0, 0, 0, 0, 0, 0, 0.4090909090909091, 0, 0, 0, 0, 0, 0, ['neighborhood'], 29]]\n",
      "Saving Dataset =============== :  75 - bawj-6bgn.BRONX_CONDOMINIUM_PROPERTY_Neighborhood.txt.gz\n",
      "Processing Dataset =========== :  76 - a5td-mswe.Vehicle_Color.txt.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4516519347285714e-07\n",
      "2.1572824592053573e-06\n",
      "0.0001787092789205718\n",
      "1.8984085641007144e-06\n",
      "[['a5td-mswe.Vehicle_Color.txt.gz', 0.002353610503282274, 0.03732129798318185, 11588654, 3.833698030634573, 0, 0, 0, 0, 0, 3.4516519347285714e-07, 0, 1.7258259673642857e-07, 0, 0, 0, 0, 0, 0, 0, 0.0001787092789205718, 0, 0, 0, 0, 2.1572824592053573e-06, 1.8984085641007144e-06, [], 2128]]\n",
      "Saving Dataset =============== :  76 - a5td-mswe.Vehicle_Color.txt.gz\n",
      "Processing Dataset =========== :  77 - jz4z-kudi.Respondent_Address__City_.txt.gz\n",
      "0.4852950761856464\n",
      "1.0297096990930832e-06\n",
      "0.5898158621630597\n",
      "0.5135474271416031\n",
      "[['jz4z-kudi.Respondent_Address__City_.txt.gz', 0.00020390395386236295, 0.010523727904105435, 9711475, 9.755947429712194, 0, 1.5445645486396248e-06, 0, 2.0594193981861663e-07, 0, 0.0007653832193358888, 3.871708468589993e-05, 8.237677592744665e-07, 2.0594193981861663e-07, 0, 0, 0, 0, 0, 0, 0.5898158621630597, 0, 0, 0, 0, 1.0297096990930832e-06, 0.5135474271416031, ['city agency', 'neighborhood', 'parks and playgrounds'], 15436062]]\n",
      "Saving Dataset =============== :  77 - jz4z-kudi.Respondent_Address__City_.txt.gz\n",
      "Processing Dataset =========== :  78 - uzcy-9puk.Street_Name.txt.gz\n",
      "6.872786103776322e-07\n",
      "1.305829359717501e-05\n",
      "1.2371014986797377e-05\n",
      "[['uzcy-9puk.Street_Name.txt.gz', 0.005758590128170272, 0.022367018240860077, 1455014, 13.270793564221435, 0, 4.742222411605661e-05, 0, 0, 0, 0.8844409744511049, 0.009441146270757532, 0.00016425958788025407, 0, 0, 0, 0, 0, 0, 0, 1.2371014986797377e-05, 0, 0, 0, 0, 1.305829359717501e-05, 0, ['street'], 1300957]]\n",
      "Saving Dataset =============== :  78 - uzcy-9puk.Street_Name.txt.gz\n",
      "Processing Dataset =========== :  79 - 6ypq-ih9a.BOROUGH.txt.gz\n",
      "[['6ypq-ih9a.BOROUGH.txt.gz', 0.5039999999999999, 0.3568325938027523, 12495, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 0]]\n",
      "Saving Dataset =============== :  79 - 6ypq-ih9a.BOROUGH.txt.gz\n",
      "Processing Dataset =========== :  80 - 5ziv-wcy4.WEBSITE.txt.gz\n",
      "[['5ziv-wcy4.WEBSITE.txt.gz', 0.03675409836065574, 0.15941389062622544, 299, 40.14754098360656, 0.6755852842809364, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 202]]\n",
      "Saving Dataset =============== :  80 - 5ziv-wcy4.WEBSITE.txt.gz\n",
      "Processing Dataset =========== :  81 - jzt2-2f7h.School_Name.txt.gz\n",
      "0.0006180469715698393\n",
      "[['jzt2-2f7h.School_Name.txt.gz', 0.005593536357986327, 0.07460367161803672, 1618, 26.987569919204475, 0, 0, 0, 0, 0, 0.05315203955500618, 0.9400494437577256, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['school_name'], 1607]]\n",
      "Saving Dataset =============== :  81 - jzt2-2f7h.School_Name.txt.gz\n",
      "Processing Dataset =========== :  82 - w6yt-hctp.COMPARABLE_RENTAL_1__Building_Classification.txt.gz\n",
      "[['w6yt-hctp.COMPARABLE_RENTAL_1__Building_Classification.txt.gz', 0.22224999999999998, 0.2954753104591128, 423, 10.666666666666666, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 423]]\n",
      "Saving Dataset =============== :  82 - w6yt-hctp.COMPARABLE_RENTAL_1__Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  83 - 2sps-j9st.PERSON_FIRST_NAME.txt.gz\n",
      "9.78952520802741e-05\n",
      "0.0004307391091532061\n",
      "0.000998531571218796\n",
      "0.0643563387175722\n",
      "[['2sps-j9st.PERSON_FIRST_NAME.txt.gz', 0.00498254044529889, 0.031323413215375455, 51075, 6.319878263655294, 0, 0, 0, 0, 0, 0.00021536955457660304, 9.78952520802741e-05, 0, 0, 0, 0, 0, 0, 0, 0, 0.000998531571218796, 0, 0, 0, 9.78952520802741e-05, 0, 0.0643563387175722, [], 3381]]\n",
      "Saving Dataset =============== :  83 - 2sps-j9st.PERSON_FIRST_NAME.txt.gz\n",
      "Processing Dataset =========== :  84 - ajgi-hpq9.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "0.7342931937172775\n",
      "0.3285340314136126\n",
      "0.5526832460732984\n",
      "0.17081151832460734\n",
      "[['ajgi-hpq9.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz', 0.3914, 0.41101617973019017, 3056, 6.6, 0, 0, 0, 0, 0, 0.18160994764397906, 0, 0, 0, 0, 0.5526832460732984, 0, 0, 0, 0, 0, 0, 0, 0, 0.3285340314136126, 0, 0.17081151832460734, ['school subject', 'area of study', 'school subject', 'parks and playgrounds'], 3770]]\n",
      "Saving Dataset =============== :  84 - ajgi-hpq9.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  85 - u553-m549.Independent_Website.txt.gz\n",
      "[['u553-m549.Independent_Website.txt.gz', 0.00477326968973747, 0.06900616192963953, 421, 32.11217183770883, 1.0, 0, 0, 0, 0, 0, 0.0665083135391924, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['website'], 449]]\n",
      "Saving Dataset =============== :  85 - u553-m549.Independent_Website.txt.gz\n",
      "Processing Dataset =========== :  86 - 7jkp-5w5g.Agency.txt.gz\n",
      "0.007326007326007326\n",
      "0.7875457875457875\n",
      "[['7jkp-5w5g.Agency.txt.gz', 0.19265909090909095, 0.23445919396851048, 273, 3.5454545454545454, 0, 0, 0, 0, 0, 0, 0, 0.003663003663003663, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.007326007326007326, 0, 0, ['city agency'], 218]]\n",
      "Saving Dataset =============== :  86 - 7jkp-5w5g.Agency.txt.gz\n",
      "Processing Dataset =========== :  87 - kiyv-ks3f.phone.txt.gz\n",
      "[['kiyv-ks3f.phone.txt.gz', 0.002009259259259255, 0.025201812554319847, 1885, 12.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['phone_number'], 1885]]\n",
      "Saving Dataset =============== :  87 - kiyv-ks3f.phone.txt.gz\n",
      "Processing Dataset =========== :  88 - 3rfa-3xsf.Incident_Zip.txt.gz\n",
      "1.8069219566314637e-06\n",
      "[['3rfa-3xsf.Incident_Zip.txt.gz', 0.050324152542372845, 0.13072783774030938, 1660282, 5.984110169491525, 0, 0.999720529404041, 0, 0, 0, 0, 0, 3.011536594385773e-06, 0, 0, 0, 0, 0, 0, 0, 1.8069219566314637e-06, 0, 0, 0, 0, 0, 0, ['zip_code'], 1659826]]\n",
      "Saving Dataset =============== :  88 - 3rfa-3xsf.Incident_Zip.txt.gz\n",
      "Processing Dataset =========== :  89 - eccv-9dzr.Telephone_Number.txt.gz\n",
      "[['eccv-9dzr.Telephone_Number.txt.gz', 0.006482758620689657, 0.053850763632103844, 772, 10.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['phone_number'], 772]]\n",
      "Saving Dataset =============== :  89 - eccv-9dzr.Telephone_Number.txt.gz\n",
      "Processing Dataset =========== :  90 - 3rfa-3xsf.Cross_Street_2.txt.gz\n",
      "2.1596903867861502e-06\n",
      "5.039277569167684e-06\n",
      "4.751318850929531e-05\n",
      "3.599483977976917e-06\n",
      "[['3rfa-3xsf.Cross_Street_2.txt.gz', 0.005102903281223087, 0.022606201597037825, 1389088, 13.072152551108058, 0, 0, 0, 0, 0, 0.861803571839941, 0.008238498928793568, 4.3193807735723005e-06, 0, 0, 0, 0, 0, 0, 0, 4.751318850929531e-05, 0, 0, 0, 0, 5.039277569167684e-06, 3.599483977976917e-06, ['street'], 1208652]]\n",
      "Saving Dataset =============== :  90 - 3rfa-3xsf.Cross_Street_2.txt.gz\n",
      "Processing Dataset =========== :  91 - w9ak-ipjd.Owner_s_Street_Name.txt.gz\n",
      "[['w9ak-ipjd.Owner_s_Street_Name.txt.gz', 0.005288362068965516, 0.03583635176337617, 49387, 17.061637931034483, 2.024824346487942e-05, 0, 0, 0, 0, 0.8366979164557474, 0.0029157470589426366, 4.049648692975884e-05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['address'], 41469]]\n",
      "Saving Dataset =============== :  91 - w9ak-ipjd.Owner_s_Street_Name.txt.gz\n",
      "Processing Dataset =========== :  92 - cspg-yi7g.ADDRESS.txt.gz\n",
      "[['cspg-yi7g.ADDRESS.txt.gz', 0.2488492429229792, 0.11181767602821727, 726880, 17.80447662936142, 0, 0.0002462579793088268, 0, 0, 0, 0.8643875192604006, 0.006875963020030817, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['address'], 633483]]\n",
      "Saving Dataset =============== :  92 - cspg-yi7g.ADDRESS.txt.gz\n",
      "Processing Dataset =========== :  93 - hy4q-igkk.School_Name.txt.gz\n",
      "[['hy4q-igkk.School_Name.txt.gz', 0.0007042253521126761, 0.026537244621713762, 1789359, 33.2112676056338, 0, 0, 0, 0, 0, 0.00021124883268254163, 0.0040031094933995915, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 7541]]\n",
      "Saving Dataset =============== :  93 - hy4q-igkk.School_Name.txt.gz\n",
      "Processing Dataset =========== :  94 - 9b9u-8989.DBA.txt.gz\n",
      "0.00019135093761959434\n",
      "0.0015308075009567547\n",
      "0.00019135093761959434\n",
      "0.00019135093761959434\n",
      "[['9b9u-8989.DBA.txt.gz', 0.0035926834253014643, 0.029844161942627494, 5226, 15.670345391375434, 0.00019135093761959434, 0, 0, 0, 0, 0.04286261002678913, 0.020283199387677, 0.00019135093761959434, 0, 0, 0, 0, 0, 0, 0, 0.00019135093761959434, 0, 0, 0, 0, 0.0015308075009567547, 0.00019135093761959434, [], 343]]\n",
      "Saving Dataset =============== :  94 - 9b9u-8989.DBA.txt.gz\n",
      "Processing Dataset =========== :  95 - ci93-uc8s.Website.txt.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ci93-uc8s.Website.txt.gz', 0.0005503558988338636, 0.014130831571006733, 6654, 27.840678479479024, 0.9954914337240758, 0, 0.00030057108506161706, 0, 0, 0.0004508566275924256, 0.0021039975954313195, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['website'], 6643]]\n",
      "Saving Dataset =============== :  95 - ci93-uc8s.Website.txt.gz\n",
      "Processing Dataset =========== :  96 - n2s5-fumm.BRONX_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz\n",
      "[['n2s5-fumm.BRONX_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz', 0.52, 0.5011985634456667, 54, 10.333333333333334, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['building_classification'], 54]]\n",
      "Saving Dataset =============== :  96 - n2s5-fumm.BRONX_CONDOMINIUM_PROPERTY_Building_Classification.txt.gz\n",
      "Processing Dataset =========== :  97 - cgz5-877h.SCHOOL_LEVEL_.txt.gz\n",
      "[['cgz5-877h.SCHOOL_LEVEL_.txt.gz', 0.4779999999999999, 0.3948411072824105, 1543, 9.0, 0, 0, 0, 0, 0, 0, 0.2825664290343487, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['school level'], 1979]]\n",
      "Saving Dataset =============== :  97 - cgz5-877h.SCHOOL_LEVEL_.txt.gz\n",
      "Processing Dataset =========== :  98 - 4d7f-74pe.Address.txt.gz\n",
      "[['4d7f-74pe.Address.txt.gz', 0.016200981615505546, 0.04526990826929338, 69787, 21.18109974211796, 2.8658632696634043e-05, 0, 4.2987949044951066e-05, 0, 0, 0.8364021952512646, 0.014501268144496825, 8.597589808990213e-05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['address'], 59393]]\n",
      "Saving Dataset =============== :  98 - 4d7f-74pe.Address.txt.gz\n",
      "Processing Dataset =========== :  99 - as69-ew8f.StartCity.txt.gz\n",
      "0.6274458028570674\n",
      "2.6405428956193393e-05\n",
      "0.6924295635182594\n",
      "0.7542050645612738\n",
      "[['as69-ew8f.StartCity.txt.gz', 0.011345177664974596, 0.07803408883298232, 75742, 11.456852791878173, 0, 0, 0, 0, 0, 0.00019804071717145045, 0.00014522985925906367, 0, 0, 0, 0, 0, 0, 0, 0, 0.6924295635182594, 0, 0, 0, 0, 2.6405428956193393e-05, 0.7542050645612738, ['city agency', 'neighborhood', 'parks and playgrounds'], 157123]]\n",
      "Saving Dataset =============== :  99 - as69-ew8f.StartCity.txt.gz\n",
      "Processing Dataset =========== :  100 - 7btz-mnc8.Provider_Last_Name.txt.gz\n",
      "0.0005154639175257732\n",
      "0.002577319587628866\n",
      "0.0010309278350515464\n",
      "[['7btz-mnc8.Provider_Last_Name.txt.gz', 0.01823917388407731, 0.06084744386072229, 1940, 6.795469686875417, 0, 0, 0, 0, 0, 0, 0.0005154639175257732, 0, 0, 0, 0, 0, 0, 0, 0, 0.002577319587628866, 0, 0, 0, 0, 0.0005154639175257732, 0.0010309278350515464, [], 9]]\n",
      "Saving Dataset =============== :  100 - 7btz-mnc8.Provider_Last_Name.txt.gz\n",
      "Processing Dataset =========== :  101 - erm2-nwe9.Park_Facility_Name.txt.gz\n",
      "3.709261585704691e-07\n",
      "5.10023468034395e-07\n",
      "[['erm2-nwe9.Park_Facility_Name.txt.gz', 0.00023293733985557886, 0.015262284883187665, 21567635, 30.47379454926625, 0, 0, 0, 0, 0, 0.00024652679813989804, 0.0010536157534194175, 0, 0, 0, 0, 0, 0, 0, 0, 3.709261585704691e-07, 0, 0, 0, 0, 0, 5.10023468034395e-07, [], 28060]]\n",
      "Saving Dataset =============== :  101 - erm2-nwe9.Park_Facility_Name.txt.gz\n",
      "Processing Dataset =========== :  102 - 6rrm-vxj9.parkname.txt.gz\n",
      "[['6rrm-vxj9.parkname.txt.gz', 0.012122562674094686, 0.06060967268072511, 1219, 21.515320334261837, 0, 0, 0, 0, 0, 0.02132895816242822, 0.018867924528301886, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 49]]\n",
      "Saving Dataset =============== :  102 - 6rrm-vxj9.parkname.txt.gz\n",
      "Processing Dataset =========== :  103 - q2ni-ztsb.Street_Address_1.txt.gz\n",
      "[['q2ni-ztsb.Street_Address_1.txt.gz', 0.03424990865911575, 0.07989101463081838, 19236, 19.470588235294116, 0, 0, 0.0001039717196922437, 0, 0, 0.8101996257018091, 0.019130796423372842, 0.0001039717196922437, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['address'], 15957]]\n",
      "Saving Dataset =============== :  103 - q2ni-ztsb.Street_Address_1.txt.gz\n",
      "Processing Dataset =========== :  104 - k3cd-yu9d.Location_1.txt.gz\n",
      "[['k3cd-yu9d.Location_1.txt.gz', 0.00932513432835825, 0.03240710789891767, 35453, 22.790208955223882, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['lat_lon_cord'], 35453]]\n",
      "Saving Dataset =============== :  104 - k3cd-yu9d.Location_1.txt.gz\n",
      "Processing Dataset =========== :  105 - fbaw-uq4e.CITY.txt.gz\n",
      "0.5204326050664151\n",
      "0.34201930754155474\n",
      "0.5202874355810408\n",
      "[['fbaw-uq4e.CITY.txt.gz', 0.012329824561403477, 0.08854184569089005, 13777, 9.459649122807017, 0, 0, 0, 0, 0, 0.002613050736735138, 0.00014516948537417434, 0, 0, 0, 0, 0, 0, 0, 0, 0.34201930754155474, 0, 0, 0, 0, 0, 0.5202874355810408, ['city agency', 'neighborhood', 'parks and playgrounds'], 19088]]\n",
      "Saving Dataset =============== :  105 - fbaw-uq4e.CITY.txt.gz\n",
      "Processing Dataset =========== :  106 - 8k4x-9mp5.Last_Name__only_2014_15_.txt.gz\n",
      "0.00020230629172567267\n",
      "0.00040461258345134534\n",
      "0.0032369006676107627\n",
      "0.013554521545620068\n",
      "[['8k4x-9mp5.Last_Name__only_2014_15_.txt.gz', 0.011873672747073221, 0.05074452057349478, 4943, 7.233052001089028, 0, 0, 0, 0, 0, 0.00020230629172567267, 0.0074853327938498885, 0, 0, 0, 0, 0, 0, 0, 0, 0.0032369006676107627, 0, 0, 0, 0, 0.00040461258345134534, 0.013554521545620068, [], 124]]\n",
      "Saving Dataset =============== :  106 - 8k4x-9mp5.Last_Name__only_2014_15_.txt.gz\n",
      "Processing Dataset =========== :  107 - 5tdj-xqd5.Borough.txt.gz\n",
      "0.6\n",
      "0.6\n",
      "0.8\n",
      "[['5tdj-xqd5.Borough.txt.gz', 0.5, 0.0, 2835, 8.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6, 0, 0, 0, 0, 0, 0.8, ['city agency', 'neighborhood', 'parks and playgrounds'], 5670]]\n",
      "Saving Dataset =============== :  107 - 5tdj-xqd5.Borough.txt.gz\n",
      "Processing Dataset =========== :  108 - uq7m-95z8.interest6.txt.gz\n",
      "0.2692307692307692\n",
      "0.038461538461538464\n",
      "[['uq7m-95z8.interest6.txt.gz', 0.3409090909090909, 0.3404542420195274, 26, 18.181818181818183, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2692307692307692, 0.038461538461538464, 0, [], 8]]\n",
      "Saving Dataset =============== :  108 - uq7m-95z8.interest6.txt.gz\n",
      "Processing Dataset =========== :  109 - 9z9b-6hvk.Borough.txt.gz\n",
      "0.10989010989010989\n",
      "0.8571428571428571\n",
      "0.9010989010989011\n",
      "[['9z9b-6hvk.Borough.txt.gz', 0.16885714285714287, 0.3671600144221538, 91, 9.142857142857142, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8571428571428571, 0, 0, 0, 0, 0, 0.9010989010989011, ['city agency', 'neighborhood', 'parks and playgrounds'], 170]]\n",
      "Saving Dataset =============== :  109 - 9z9b-6hvk.Borough.txt.gz\n",
      "Processing Dataset =========== :  110 - 2bnn-yakx.Vehicle_Make.txt.gz\n",
      "1.8639361989550588e-07\n",
      "1.8639361989550587e-06\n",
      "9.086688969905912e-05\n",
      "3.951544741784725e-05\n",
      "4.5200452824660175e-05\n",
      "[['2bnn-yakx.Vehicle_Make.txt.gz', 0.0014638723254998248, 0.02715992402460123, 10729981, 4.332690284110838, 0, 9.319680994775294e-07, 0, 0, 0, 9.319680994775294e-08, 1.9571330089028115e-06, 2.982297918328094e-06, 0, 0, 1.8639361989550588e-07, 0, 0, 0, 0, 3.951544741784725e-05, 0, 0, 0, 0, 9.086688969905912e-05, 4.5200452824660175e-05, [], 1970]]\n",
      "Saving Dataset =============== :  110 - 2bnn-yakx.Vehicle_Make.txt.gz\n",
      "Processing Dataset =========== :  111 - uwyv-629c.StreetName.txt.gz\n",
      "[['uwyv-629c.StreetName.txt.gz', 0.011937778603268905, 0.03535175055221583, 1828561, 13.467496285289748, 0, 0, 0, 0, 0, 0.8784623537306111, 0.010731389327454759, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['street'], 1625945]]\n",
      "Saving Dataset =============== :  111 - uwyv-629c.StreetName.txt.gz\n",
      "Processing Dataset =========== :  112 - 6wcu-cfa3.CORE_COURSE__MS_CORE_and_9_12_ONLY_.txt.gz\n",
      "0.17593961148648649\n",
      "0.07823057432432433\n",
      "[['6wcu-cfa3.CORE_COURSE__MS_CORE_and_9_12_ONLY_.txt.gz', 0.0702272727272727, 0.20793747499306978, 18944, 11.181818181818182, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07823057432432433, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], 1482]]\n",
      "Saving Dataset =============== :  112 - 6wcu-cfa3.CORE_COURSE__MS_CORE_and_9_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  113 - 8wbx-tsch.Website.txt.gz\n",
      "[['8wbx-tsch.Website.txt.gz', 0.020525896414342572, 0.09961105524334754, 72690, 19.9203187250996, 0.99889943596093, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['website'], 72610]]\n",
      "Saving Dataset =============== :  113 - 8wbx-tsch.Website.txt.gz\n",
      "Processing Dataset =========== :  114 - rbx6-tga4.Owner_Street_Address.txt.gz\n",
      "2.5251249936871874e-05\n",
      "0.0001262562496843594\n",
      "0.0001262562496843594\n",
      "[['rbx6-tga4.Owner_Street_Address.txt.gz', 0.003337313852205762, 0.026650863539309087, 39602, 16.424416971059287, 0, 0, 0, 0.0001262562496843594, 0, 0.8627342053431645, 0.001818089995454775, 0.002676632493308419, 0, 0, 0, 0, 0, 0, 0, 0.0001262562496843594, 0, 0, 0, 0, 0, 0.0001262562496843594, ['address'], 34360]]\n",
      "Saving Dataset =============== :  114 - rbx6-tga4.Owner_Street_Address.txt.gz\n",
      "Processing Dataset =========== :  115 - 735p-zed8.CANDMI.txt.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08841201716738198\n",
      "[['735p-zed8.CANDMI.txt.gz', 0.2984166666666666, 0.3098738756987747, 116500, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.08841201716738198, 0, 0, 0, 0, 0, 0, [], 10300]]\n",
      "Saving Dataset =============== :  115 - 735p-zed8.CANDMI.txt.gz\n",
      "Processing Dataset =========== :  116 - t8hj-ruu2.Business_Phone_Number.txt.gz\n",
      "[['t8hj-ruu2.Business_Phone_Number.txt.gz', 0.002490516866946839, 0.015247083634339442, 65101, 9.997997200907292, 0, 1.5360747146741216e-05, 0, 0.9985560897682063, 0, 0, 0, 0.00010752523002718852, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['phone_number'], 65015]]\n",
      "Saving Dataset =============== :  116 - t8hj-ruu2.Business_Phone_Number.txt.gz\n",
      "Processing Dataset =========== :  117 - i5ef-jxv3.Agency.txt.gz\n",
      "0.010704225352112675\n",
      "0.7785915492957747\n",
      "[['i5ef-jxv3.Agency.txt.gz', 0.3435625, 0.24034778933958495, 1775, 3.7291666666666665, 0, 0, 0, 0, 0, 0, 0, 0.007323943661971831, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.010704225352112675, 0, 0, ['city agency'], 1414]]\n",
      "Saving Dataset =============== :  117 - i5ef-jxv3.Agency.txt.gz\n",
      "Processing Dataset =========== :  118 - 7yds-6i8e.CORE_SUBJECT__MS_CORE_and_9_12_ONLY_.txt.gz\n",
      "0.7659574468085106\n",
      "0.40425531914893614\n",
      "0.5623100303951368\n",
      "0.20212765957446807\n",
      "[['7yds-6i8e.CORE_SUBJECT__MS_CORE_and_9_12_ONLY_.txt.gz', 0.552, 0.35681928199019736, 658, 6.6, 0, 0, 0, 0, 0, 0.20364741641337386, 0, 0, 0, 0, 0.5623100303951368, 0, 0, 0, 0, 0, 0, 0, 0, 0.40425531914893614, 0, 0.20212765957446807, ['school subject', 'area of study', 'school subject', 'parks and playgrounds'], 903]]\n",
      "Saving Dataset =============== :  118 - 7yds-6i8e.CORE_SUBJECT__MS_CORE_and_9_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  119 - s3k6-pzi2.interest1.txt.gz\n",
      "0.10909090909090909\n",
      "0.00909090909090909\n",
      "0.029545454545454545\n",
      "[['s3k6-pzi2.interest1.txt.gz', 0.10005000000000001, 0.21838461363769246, 440, 16.4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00909090909090909, 0, 0, 0, 0, 0, 0, 0, 0, 0.10909090909090909, 0.029545454545454545, 0, [], 65]]\n",
      "Saving Dataset =============== :  119 - s3k6-pzi2.interest1.txt.gz\n",
      "Processing Dataset =========== :  120 - ji82-xba5.address.txt.gz\n",
      "[['ji82-xba5.address.txt.gz', 0.015341325692132311, 0.03767298087022423, 36419, 18.208714339892968, 0, 0, 5.491638979653478e-05, 0, 0, 0.8801175210741646, 0.007605919986820067, 2.745819489826739e-05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['address'], 32333]]\n",
      "Saving Dataset =============== :  120 - ji82-xba5.address.txt.gz\n",
      "Processing Dataset =========== :  121 - 3aka-ggej.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "0.5615742699957681\n",
      "0.28015234870926786\n",
      "0.42149809564113416\n",
      "0.1396529834955565\n",
      "[['3aka-ggej.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz', 0.20199999999999996, 0.44610144586181294, 2363, 6.6, 0, 0, 0, 0, 0, 0.14007617435463393, 0, 0, 0, 0, 0.42149809564113416, 0, 0, 0, 0, 0, 0, 0, 0, 0.28015234870926786, 0, 0.1396529834955565, ['school subject', 'school subject', 'parks and playgrounds'], 2319]]\n",
      "Saving Dataset =============== :  121 - 3aka-ggej.CORE_SUBJECT___MS_CORE_and__09_12_ONLY_.txt.gz\n",
      "Processing Dataset =========== :  122 - dm9a-ab7w.AUTH_REP_FIRST_NAME.txt.gz\n",
      "5.8621801447958495e-05\n",
      "0.0004103526101357095\n",
      "5.8621801447958495e-05\n",
      "0.00026379810651581324\n",
      "0.00011724360289591699\n",
      "0.0012896796318550869\n",
      "0.041123193715742884\n",
      "[['dm9a-ab7w.AUTH_REP_FIRST_NAME.txt.gz', 0.00237738273720282, 0.022437903703905984, 34117, 6.113300492610837, 0, 0, 0, 0, 0, 5.8621801447958495e-05, 5.8621801447958495e-05, 0, 0, 0, 5.8621801447958495e-05, 0, 0, 0, 0, 0.0012896796318550869, 0, 0, 0, 0.0004103526101357095, 0.00011724360289591699, 0.041123193715742884, [], 1480]]\n",
      "Saving Dataset =============== :  122 - dm9a-ab7w.AUTH_REP_FIRST_NAME.txt.gz\n",
      "Processing Dataset =========== :  123 - kwmq-dbub.CANDMI.txt.gz\n",
      "0.06731242494044455\n",
      "[['kwmq-dbub.CANDMI.txt.gz', 0.2515909090909091, 0.2546892895257557, 50793, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06731242494044455, 0, 0, 0, 0, 0, 0, [], 3419]]\n",
      "Saving Dataset =============== :  123 - kwmq-dbub.CANDMI.txt.gz\n",
      "Processing Dataset =========== :  124 - n5mv-nfpy.Location1.txt.gz\n",
      "[['n5mv-nfpy.Location1.txt.gz', 0.010264686359110691, 0.04000036685569787, 7394, 22.78128111516761, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ['lat_lon_cord'], 7394]]\n",
      "Saving Dataset =============== :  124 - n5mv-nfpy.Location1.txt.gz\n",
      "Processing Dataset =========== :  125 - bty7-2jhb.Owner_s_House_Zip_Code.txt.gz\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o86270.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5746.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5746.0 (TID 5754, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<count_double_VectorAssembler_0d7c2cc76290:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 29 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1161)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1137)\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeColumnSummaryStatistics(RowMatrix.scala:433)\n\tat org.apache.spark.mllib.stat.Statistics$.colStats(Statistics.scala:46)\n\tat org.apache.spark.ml.feature.MinMaxScaler.fit(MinMaxScaler.scala:123)\n\tat org.apache.spark.ml.feature.MinMaxScaler.fit(MinMaxScaler.scala:93)\n\tat sun.reflect.GeneratedMethodAccessor120.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<count_double_VectorAssembler_0d7c2cc76290:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 29 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e9d82e03ff39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mregex_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"false\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferSchema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delimiter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomSchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputDirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_stdv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-249f432d9f76>\u001b[0m in \u001b[0;36mmean_stdv\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_Vect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_Scaled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massembler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_Scaled\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_Scaled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_Vect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mdf_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count_Scaled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_stddev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count_Scaled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/frameworks/spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/frameworks/spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/frameworks/spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/frameworks/spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/frameworks/spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1286\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/frameworks/spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o86270.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5746.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5746.0 (TID 5754, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<count_double_VectorAssembler_0d7c2cc76290:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 29 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1161)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1137)\n\tat org.apache.spark.mllib.linalg.distributed.RowMatrix.computeColumnSummaryStatistics(RowMatrix.scala:433)\n\tat org.apache.spark.mllib.stat.Statistics$.colStats(Statistics.scala:46)\n\tat org.apache.spark.ml.feature.MinMaxScaler.fit(MinMaxScaler.scala:123)\n\tat org.apache.spark.ml.feature.MinMaxScaler.fit(MinMaxScaler.scala:93)\n\tat sun.reflect.GeneratedMethodAccessor120.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<count_double_VectorAssembler_0d7c2cc76290:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1145)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1146)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 29 more\n"
     ]
    }
   ],
   "source": [
    "    #Testing first 10 files\n",
    "    for filerow in raw_list:\n",
    "        filename = filerow[0]\n",
    "        labels = literal_eval(filerow[1])\n",
    "        print(\"Processing Dataset =========== : \", str(processCount) + ' - ' +filename)\n",
    "        # Read file to dataset and apply all regex functions\n",
    "        found_type = []\n",
    "        fileinfo = []\n",
    "        regex_res = []\n",
    "        df = sqlContext.read.format(\"csv\").option(\"header\",\"false\").option(\"inferSchema\", \"true\").option(\"delimiter\", \"\\t\").schema(customSchema).load(inputDirectory + filename)\n",
    "        df_stats = mean_stdv(df)\n",
    "        mean = df_stats[0]['mean']\n",
    "        std = df_stats[0]['std']\n",
    "        count_all = count_all_values(df)\n",
    "\n",
    "        #added col_length which is the average length of the col\n",
    "        df_length = df.select(_mean(length(col(\"val\"))).alias('avg_length'))\n",
    "        col_length= df_length.collect()[0][0]\n",
    "\n",
    "        percentage_website, found_type, type_count_web = re_find_website(df,count_all,found_type)\n",
    "        percentage_zip, found_type, type_count_zip = re_find_zipCode(df,count_all,found_type)\n",
    "        percentage_buildingCode, found_type,type_count_building = re_find_buildingCode(df,count_all,found_type)\n",
    "        percentage_phoneNum, found_type, type_count_phone = re_find_phoneNum(df,count_all,found_type)\n",
    "        percentage_lat_lon, found_type, type_count_lat_lon = re_find_lat_lon(df,count_all,found_type)\n",
    "        percentage_add_st, found_type, type_count_add_st = re_find_street_address(df,count_all,col_length,found_type)\n",
    "        percentage_school_name, found_type, type_count_school_name= re_find_school(df,count_all,found_type)\n",
    "        percentage_house_no, found_type ,type_count_house_no= re_find_houseNo(df,count_all,found_type)\n",
    "        percentage_school_lvl, found_type, type_count_school_lvl= re_find_schoolLevel(df,count_all,found_type)\n",
    "        percentage_school_subject, found_type, type_count_school_subject= re_find_school_subject(df,count_all,found_type)\n",
    "        \n",
    "        # moved this block up here -ted\n",
    "        percentage_area_of_study, found_type, type_count_area_of_study = list_find_area_of_study(df,count_all,found_type)\n",
    "        percentage_school_subject, found_type, type_count_school_subject= list_find_school_subject(df,count_all,found_type)\n",
    "        percentage_agency, found_type, type_count_agency= list_find_agency(df,count_all,found_type)\n",
    "        percentage_location, found_type, type_count_location= list_find_location_type(df,count_all,found_type)\n",
    "        percentage_neighborhood, found_type, type_count_neighborhood= list_find_neighborhood(df,count_all,found_type)\n",
    "        percentage_parks_playgrounds, found_type, type_count_parks_playgrounds = list_find_parks_playgrounds(df,count_all,found_type)\n",
    "        \n",
    "        type_count = type_count_web + type_count_zip + type_count_building + type_count_phone + \\\n",
    "                    type_count_lat_lon + type_count_add_st + type_count_school_name + \\\n",
    "                    type_count_house_no + type_count_school_lvl + type_count_school_subject + \\\n",
    "                    type_count_area_of_study + type_count_neighborhood + type_count_agency + \\\n",
    "                    type_count_location + type_count_parks_playgrounds\n",
    "        \n",
    "        #give a default value for all other precentages \n",
    "        percentage_person = 0\n",
    "        percentage_business_name = 0\n",
    "        percentage_vehicle_type = 0\n",
    "        percentage_color = 0\n",
    "        percentage_car_make = 0\n",
    "        percentage_car_model = 0\n",
    "        #percentage_neighborhood = 0\n",
    "        percentage_borough= 0 \n",
    "        percentage_city = 0\n",
    "        #percentage_area_of_study = 0\n",
    "        #percentage_location = 0\n",
    "        #percentage_agency = 0\n",
    "        #percentage_parks_playgrounds = 0\n",
    "\n",
    "        #STEP TWO: NLP LABEL AND LIST CHECK\n",
    "        # if not found_type:\n",
    "        #     #ANKUSH PART: NLP CHECK TYPES\n",
    "        #     percentage_person, found_type, type_count_person = nlp_find_person(df,count_all,found_type)\n",
    "        #     percentage_business_name, found_type, type_count_business = nlp_find_business_name(df,count_all,found_type)\n",
    "        #     percentage_vehicle_type, found_type, type_count_vehicle_type = nlp_find_vehicle_type(df,count_all,found_type)\n",
    "        #     percentage_color, found_type, type_count_color = nlp_find_color(df,count_all,found_type)\n",
    "        #     percentage_car_make, found_type, type_count_car_make = nlp_find_car_make(df,count_all,found_type)\n",
    "        #     percentage_car_model, found_type, type_count_car_model = nlp_find_car_model(df,count_all,found_type)\n",
    "        #     percentage_neighborhood, found_type, type_count_neighborhood = nlp_find_neighborhood(df,count_all,found_type)\n",
    "        #     percentage_borough, found_type, type_count_borough = nlp_find_borough(df,count_all,found_type)\n",
    "        #     percentage_city, found_type, type_count_city = nlp_find_city(df,count_all,found_type)\n",
    "        \n",
    "        #     #TED PART: LIST or SIMILARITY CHECK TYPEs\n",
    "        #   percentage_school_subject, found_type, type_count_school_subject= list_find_school_subject(df,count_all,found_type)\n",
    "        #     percentage_business_name, found_type, type_count_business= list_find_business_name(df,count_all,found_type)\n",
    "        #   percentage_neighborhood, found_type, type_count_neighborhood= list_find_neighborhood(df,count_all,found_type)\n",
    "        #   percentage_area_of_study, found_type, type_count_area_of_study = list_find_area_of_study(df,count_all,found_type)\n",
    "        #   percentage_agency, found_type, type_count_agency= list_find_agency(df,count_all,found_type)\n",
    "        #   percentage_location, found_type, type_count_location= list_find_location_type(df,count_all,found_type)\n",
    "        #   percentage_parks_playgrounds, type_count_location_parks_playgrounds = list_find_parks_playgrounds(df,count_all,found_type\n",
    "        # !!! NOTE: Please remeber to add type_count_XXX back to type_count in LINE 347\n",
    "        fileinfo.extend([filename,mean,std,count_all,col_length, percentage_website, percentage_zip,percentage_buildingCode,percentage_phoneNum,percentage_lat_lon,percentage_add_st,percentage_school_name,percentage_house_no,percentage_school_lvl,percentage_person,percentage_school_subject,percentage_vehicle_type, percentage_color,percentage_car_make,percentage_car_model,percentage_neighborhood,percentage_borough,percentage_city,percentage_business_name,percentage_area_of_study,percentage_location,percentage_parks_playgrounds,found_type, type_count])\n",
    "        regex_res.append(fileinfo)\n",
    "        print(regex_res)\n",
    "        # USE ME to export the JSON for current dataset\n",
    "        print(\"Saving Dataset =============== : \", str(processCount) + ' - ' +filename)\n",
    "        processCount += 1\n",
    "        #outJSON = deepcopy(jsonSchema)\n",
    "        #outJSON[\"column_name\"] = filename\n",
    "        #outJSON[\"semantic_type\"] = found_type\n",
    "        #outJSON[\"count\"] = type_count\n",
    "        #outJSON = sc.parallelize([json.dumps(outJSON)])\n",
    "        #outJSON.saveAsTextFile(outputDirectory + filename + '/task2.json')\n",
    "\n",
    "\n",
    "\n",
    "    # Output regex function result \n",
    "    rdd = sc.parallelize(regex_res)\n",
    "    row_rdd = rdd.map(lambda x: Row(x))\n",
    "    df = row_rdd.toDF()\n",
    "    df = df.select(col('_1').alias('coln'))\n",
    "    length = len(df.select('coln').take(1)[0][0])\n",
    "    df = df.select([df.coln[i] for i in range(length)])\n",
    "    df = df.select(col('coln[0]').alias('filename'),col('coln[1]').alias('mean'),col('coln[2]').alias('stdv'),\n",
    "               col('coln[3]').alias('count_all'),col('coln[4]').alias('col_length'),col('coln[5]').alias('precentage_website'),\n",
    "               col('coln[6]').alias('precentage_zip'),col('coln[7]').alias('percentage_buildingCode'),col('coln[8]').alias('percentage_phoneNum'),\n",
    "               col('coln[9]').alias('percentage_lat_lon'),col('coln[10]').alias('percentage_add_st'),col('coln[11]').alias('percentage_school_name'),\n",
    "               col('coln[12]').alias('percentage_houseNo'),col('coln[13]').alias('percentage_school_lvl'),col('coln[14]').alias('percentage_person'),\n",
    "               col('coln[15]').alias('percentage_school_subject'),col('coln[16]').alias('percentage_vehicle_type'),col('coln[17]').alias('percentage_color'),\n",
    "               col('coln[18]').alias('percentage_car_make'),col('coln[19]').alias('percentage_car_model'),\n",
    "               col('coln[20]').alias('percentage_neighborhood'),col('coln[21]').alias('percentage_borough'),col('coln[22]').alias('percentage_city'),\n",
    "               col('coln[23]').alias('percentage_business_name'),col('coln[24]').alias('percentage_area_of_study'),col('coln[25]').alias('percentage_location_type'),\n",
    "               col('coln[26]').alias('percentage_parks_playgrounds'),col('coln[27]').alias('types'), col('coln[28]').alias('types_count')\n",
    "               )\n",
    "\n",
    "    types_found_count = df.where(col('types') > \" \").count()\n",
    "    print(types_found_count)\n",
    "    #df.write.csv('regex_res.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
